{
  "resetToDefault": "Reset",
  "showAll": "All",
  "basicSettings": "Basic",
  "advancedTab/overridesTitle": "Config Overrides",
  "advancedTab/noConfigsText": "You have no unsaved changes - edit values above to see overrides here.",
  "noListedConfigs": "No configurable parameters",
  "loadParameters/reload": "Reload to apply changes",
  "loadParameters/reload/error": "Failed to reload the model",
  "discardChanges": "Discard changes",
  "schematicsError.title": "The config schematics contains errors in the following fields:",
  "manifestSections": {
    "structuredOutput/title": "Structured Output",
    "speculativeDecoding/title": "Speculative Decoding",
    "sampling/title": "Sampling",
    "settings/title": "Settings",
    "toolUse/title": "Tool Use",
    "promptTemplate/title": "Prompt Template",
    "customFields/title": "Custom Fields"
  },
  "llm.prediction.systemPrompt/title": "System Prompt",
  "llm.prediction.systemPrompt/description": "Use this field to provide background instructions to the model, such as a set of rules, constraints, or general requirements.",
  "llm.prediction.systemPrompt/openEditor": "Editor",
  "llm.prediction.systemPrompt/closeEditor": "Close Editor",
  "llm.prediction.maxPredictedTokens/inputLabel": "Maximum response length (tokens)",
  "llm.prediction.stopStrings/placeholder": "Enter a string and press ⏎",
  "llm.prediction.structured/description": "Advanced: you can provide a [JSON Schema](https://json-schema.org/learn/miscellaneous-examples) to enforce a particular output format from the model. Read the [documentation](https://lmstudio.ai/docs/advanced/structured-output) to learn more",
  "llm.prediction.tools/description": "Advanced: you can provide a JSON-compliant list of tools for the model to request calls to. Read the [documentation](https://lmstudio.ai/docs/advanced/tool-use) to learn more",
  "load.gpuStrictVramCap.customSubTitleOff": "OFF: Allow model weights to offload to shared memory if dedicated GPU memory is full",
  "load.gpuStrictVramCap.customSubTitleOn": "ON: The system will limit offload of model weights to dedicated GPU memory and RAM only. Context may still use shared memory",
  "load.gpuStrictVramCap.customGpuOffloadWarning": "Model offload limited to dedicated GPU memory. Actual number of offloaded layers may differ",
  "load.allGpusDisabledWarning": "All GPUs are currently disabled. Enable at least one to offload",
  "llm.load.contextLength/warning": "Setting a high value for context length can significantly impact memory usage",
  "llm.load.llama.vCacheQuantizationType/turnedOnWarning": "⚠️ You must disable this value if Flash Attention is not enabled",
  "llm.load.llama.vCacheQuantizationType/disabledMessage": "Can only be turned on when Flash Attention is enabled",
  "llm.load.llama.vCacheQuantizationType/invalidF32MetalState": "⚠️ You must disable flash attention when using F32",
  "llm.load.mlx.kvCacheBits/turnedOnWarning": "Context Length setting is ignored when using KV Cache Quantization",
  "presetTooltip": {
    "included/title": "Preset Values",
    "included/description": "The following fields will be applied",
    "included/empty": "No fields of this preset apply in this context.",
    "included/conflict": "You will be asked to choose whether to apply this value",
    "separateLoad/title": "Load-time Configuration",
    "separateLoad/description.1": "The preset also includes the following load-time configuration. Load time config are model-wide and requires reloading the model to take effect. Hold",
    "separateLoad/description.2": "to apply to",
    "separateLoad/description.3": ".",
    "excluded/title": "May not apply",
    "excluded/description": "The following fields are included in the preset but does not apply in the current context.",
    "legacy/title": "Legacy Preset",
    "legacy/description": "This preset is a legacy preset. It includes the following fields which are either handled automatically now, or are no longer applicable.",
    "button/publish": "Publish to Hub",
    "button/pushUpdate": "Push Changes to Hub",
    "button/noChangesToPush": "No changes to push",
    "hubLabel": "Preset from the Hub by {{user}}",
    "ownHubLabel": "Your preset from the Hub"
  },
  "customInputs": {
    "llmPromptTemplate": {
      "types.jinja/label": "Template (Jinja)",
      "jinja/error": "Failed to parse Jinja template: {{error}}",
      "jinja/empty": "Please enter a Jinja template above.",
      "jinja/unlikelyToWork": "The Jinja template you provided above is unlikely to work as it does not reference the variable \"messages\". Please double check if you have entered a correct template.",
      "types.manual/label": "Manual",
      "stopStrings/label": "Additional Stop Strings"
    },
    "contextLength": {
      "maxValueTooltip": "This is the maximum number of tokens the model was trained to handle. Click to set the context to this value",
      "maxValueTextStart": "Model supports up to",
      "maxValueTextEnd": "tokens"
    },
    "contextOverflowPolicy": {
      "stopAtLimit": "Stop at Limit",
      "stopAtLimitSub": "Stop generating once the model's memory gets full",
      "truncateMiddle": "Truncate Middle",
      "truncateMiddleSub": "Removes messages from the middle of the conversation to make room for newer ones. The model will still remember the beginning of the conversation",
      "rollingWindow": "Rolling Window",
      "rollingWindowSub": "The model will always get the most recent few messages but may forget the beginning of the conversation"
    },
    "speculativeDecodingDraftModel": {
      "readMore": "Read how it works",
      "placeholder": "Select a compatible draft model",
      "noCompatible": "No compatible draft models found for your current model selection",
      "stillLoading": "Identifying compatible draft models...",
      "notCompatible": "The selected draft model (<draft/>) is not compatible with the current model selection (<current/>).",
      "compatibleWithNumberOfModels": "Recommended for at least {{dynamicValue}} of your models",
      "recommendedForSomeModels": "Recommended for some models",
      "recommendedForLlamaModels": "Recommended for Llama models",
      "recommendedForQwenModels": "Recommended for Qwen models",
      "onboardingModal": {
        "introducing": "Introducing",
        "speculativeDecoding": "Speculative Decoding",
        "firstStepBody": "Inference speedup for <custom-span>llama.cpp</custom-span> and <custom-span>MLX</custom-span> models",
        "secondStepTitle": "Inference Speedup with Speculative Decoding",
        "secondStepBody": "Speculative Decoding is a technique involving the collaboration of two models:\n - A larger \"main\" model\n - A smaller \"draft\" model\n\nDuring generation, the draft model rapidly proposes tokens for the larger main model to verify. Verifying tokens is a much faster process than actually generating them, which is the source of the speed gains. **Generally, the larger the size difference between the main model and the draft model, the greater the speed-up**.\n\nTo maintain quality, the main model only accepts tokens that align with what it would have generated itself, enabling the response quality of the larger model at faster inference speeds. Both models must share the same vocabulary.",
        "draftModelRecommendationsTitle": "Draft model recommendations",
        "basedOnCurrentModels": "Based on your current models",
        "close": "Close",
        "next": "Next",
        "done": "Done"
      },
      "speculativeDecodingLoadModelToSeeOptions": "Please load a model first <model-badge /> ",
      "errorEngineNotSupported": "Speculative decoding requires at least version {{minVersion}} of the engine {{engineName}}. Please update the engine (<key/>) and reload the model to use this feature.",
      "errorEngineNotSupported/noKey": "Speculative decoding requires at least version {{minVersion}} of the engine {{engineName}}. Please update the engine and reload the model to use this feature."
    },
    "llmReasoningParsing": {
      "startString/label": "Start String",
      "startString/placeholder": "Enter the start string...",
      "endString/label": "End String",
      "endString/placeholder": "Enter the end string..."
    }
  },
  "saveConflictResolution": {
    "title": "Choose which values to include in the Preset",
    "description": "Pick and choose which values to keep",
    "instructions": "Click on a value to include it",
    "userValues": "Previous Value",
    "presetValues": "New Value",
    "confirm": "Confirm",
    "cancel": "Cancel"
  },
  "applyConflictResolution": {
    "title": "Which values to keep?",
    "description": "You have uncommitted changes which overlap with the incoming Preset",
    "instructions": "Click on a value to keep it",
    "userValues": "Current Value",
    "presetValues": "Incoming Preset Value",
    "confirm": "Confirm",
    "cancel": "Cancel"
  },
  "noModelSelected": "No models selected",
  "apiIdentifier.label": "API Identifier",
  "apiIdentifier.hint": "Optionally provide an identifier for this model. This will be used in API requests. Leave blank to use the default identifier.",
  "idleTTL.label": "Auto Unload If Idle (TTL)",
  "idleTTL.hint": "If set, the model will be automatically unloaded after being idle for the specified amount of time.",
  "idleTTL.mins": "mins",
  "presets": {
    "title": "Preset",
    "commitChanges": "Commit Changes",
    "commitChanges/description": "Commit your changes to the preset.",
    "commitChanges.manual": "New fields detected. You will be able to choose which changes to include in the preset.",
    "commitChanges.manual.hold.0": "Hold",
    "commitChanges.manual.hold.1": "to choose which changes to commit to the preset.",
    "commitChanges.saveAll.hold.0": "Hold",
    "commitChanges.saveAll.hold.1": "to save all changes.",
    "commitChanges.saveInPreset.hold.0": "Hold",
    "commitChanges.saveInPreset.hold.1": "to only save changes to fields that are already included in the preset.",
    "commitChanges/error": "Failed to commit changes to the preset.",
    "commitChanges.manual/description": "Choose which changes to include in the preset.",
    "saveAs": "Save As New...",
    "presetNamePlaceholder": "Enter a name for the preset...",
    "cannotCommitChangesNoChanges": "No changes to commit.",
    "emptyNoUnsaved": "Select a Preset...",
    "emptyWithUnsaved": "Unsaved Preset",
    "saveEmptyWithUnsaved": "Save Preset As...",
    "saveConfirm": "Save",
    "saveCancel": "Cancel",
    "saving": "Saving...",
    "save/error": "Failed to save preset.",
    "deselect": "Deselect Preset",
    "deselect/error": "Failed to deselect preset.",
    "select/error": "Failed to select preset.",
    "delete/error": "Failed to delete preset.",
    "discardChanges": "Discard Unsaved",
    "discardChanges/info": "Discard all uncommitted changes and restore the preset to its original state",
    "newEmptyPreset": "+ New Preset",
    "importPreset": "Import",
    "contextMenuCopyIdentifier": "Copy Preset Identifier",
    "contextMenuDelete": "Delete...",
    "contextMenuShare": "Publish...",
    "contextMenuOpenInHub": "View on Web",
    "contextMenuRevealInExplorer": "Reveal in File Explorer",
    "contextMenuRevealInFinder": "Reveal in Finder",
    "share": {
      "title": "Publish Preset",
      "action": "Share your preset for others to download, like, and fork",
      "uploadAs": "Your preset will be created as {{name}}",
      "presetNameLabel": "Preset Name",
      "descriptionLabel": "Description (optional)",
      "loading": "Publishing...",
      "success": "Preset Successfully Pushed",
      "presetIsLive": "<preset-name /> is now live on the Hub!",
      "close": "Close",
      "confirmViewOnWeb": "View on web",
      "confirmCopy": "Copy URL",
      "confirmCopied": "Copied!",
      "descriptionPlaceholder": "Enter a description...",
      "willBePublic": "This preset will be public. Anyone on the internet will be able to see it.",
      "willBePrivate": "Only you will be able to see this preset",
      "willBeOrgVisible": "This preset will be visible to everyone in the organization.",
      "publicSubtitle": "Your preset is <custom-bold>Public</custom-bold>. Others can download and fork it on lmstudio.ai",
      "privateUsageReached": "Private preset number limit reached.",
      "continueInBrowser": "Continue in Browser",
      "confirmShareButton": "Publish"
    },
    "update": {
      "title": "Push Changes to Hub",
      "title/success": "Preset Successfully Updated",
      "subtitle": "Make changes to <custom-preset-name /> and push them to the Hub",
      "descriptionLabel": "Description",
      "descriptionPlaceholder": "Enter a description...",
      "loading": "Pushing...",
      "cancel": "Cancel",
      "createFreeAccount": "Create a free account in the Hub to publish presets",
      "error": "Failed to push update",
      "confirmUpdateButton": "Push"
    },
    "resolve": {
      "title": "Resolve conflicts...",
      "tooltip": "Open a modal to resolve differences with the Hub version"
    },
    "loginToManage": {
      "title": "Login to manage..."
    },
    "downloadFromHub": {
      "title": "Download",
      "downloading": "Downloading...",
      "success": "Downloaded!",
      "error": "Failed to download"
    },
    "push": {
      "title": "Push changes",
      "pushing": "Pushing...",
      "success": "Pushed",
      "tooltip": "Push your local changes to the remote version hosted on the Hub",
      "error": "Failed to push"
    },
    "saveAsNewModal": {
      "title": "Oops! Did not find the preset on Hub",
      "confirmSaveAsNewDescription": "Do you want to publish this preset as a new one?",
      "confirmButton": "Publish as New"
    },
    "pull": {
      "title": "Pull Latest",
      "error": "Failed to pull",
      "success": "Pulled",
      "pulling": "Pulling...",
      "upToDate": "Up to date!",
      "unsavedChangesModal": {
        "title": "You have unsaved changes.",
        "bodyContent": "Pulling from remote will overwrite your unsaved changes. Continue?",
        "confirmButton": "Overwrite Unsaved Changes"
      }
    },
    "import": {
      "title": "Import a Preset from File",
      "dragPrompt": "Drag and drop preset files (.tar.gz or preset.json) or <custom-link>select from your computer</custom-link>",
      "cancel": "Cancel",
      "selectDialog": {
        "title": "Select Preset File (preset.json or .tar.gz)",
        "button": "Import"
      },
      "error": "Failed to import preset",
      "resultsModal": {
        "titleAllFailed": "Failed to import presets",
        "importMore": "Import More",
        "close": "Done",
        "alreadyExistsBadge": "Preset already exists",
        "invalidFileBadge": "Invalid file",
        "otherErrorBadge": "Failed to import preset",
        "useInChat": "Use in Chat"
      },
      "importFromUrl": {
        "button": "Import from URL...",
        "title": "Import from URL",
        "back": "Import from File...",
        "action": "Paste the LM Studio Hub URL of the preset you want to import below",
        "invalidUrl": "Invalid URL. Please make sure you are pasting a correct LM Studio Hub URL.",
        "confirm": "Import",
        "cancel": "Cancel"
      }
    },
    "download": {
      "title": "Pull <preset-name /> from LM Studio Hub",
      "subtitle": "Save <custom-name /> to your presets. Doing so you will allow you to use this preset in the app",
      "button": "Pull",
      "button/loading": "Pulling...",
      "cancel": "Cancel",
      "error": "Failed to download preset."
    },
    "inclusiveness": {
      "speculativeDecoding": "Include in Preset"
    }
  },
  "hardware": {
    "environmentVariables": "Environment Variables",
    "environmentVariables.info": "If you're unsure, leave these at their default values",
    "environmentVariables.reset": "Reset to default",
    "gpus.information": "Configure graphics processing units (GPUs) detected on your machine",
    "gpuSettings": {
      "editMaxCapacity": "Edit Max Capacity",
      "hideEditMaxCapacity": "Hide Edit Max Capacity",
      "split": {
        "title": "Strategy",
        "placeholder": "Select a GPU memory allocation",
        "options": {
          "generalDescription": "Configure how models will be loaded onto your GPUs",
          "evenly": {
            "title": "Split evenly",
            "description": "Allocate memory evenly across GPUs"
          },
          "priorityOrder": {
            "title": "Priority order",
            "description": "Drag to reorder priority. The system will try to allocate more on GPUs listed first"
          },
          "custom": {
            "title": "Custom",
            "description": "Allocate memory",
            "maxAllocation": "Maximum Allocation"
          }
        }
      },
      "deviceId.info": "Unique identifier for this device",
      "changesOnlyAffectNewlyLoadedModels": "Changes will only affect newly loaded models",
      "toggleGpu": "Enable/Disable GPU"
    }
  },
  "envVars": {
    "select": {
      "placeholder": "Select an environment variable...",
      "noOptions": "No more available",
      "filter": {
        "placeholder": "Filter search results"
      }
    },
    "inputValue": {
      "placeholder": "Enter a value"
    },
    "values": {
      "title": "Current Values"
    }
  }
}